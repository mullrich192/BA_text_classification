{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction\n",
    "### extract keywords from MeSH and AGROVOC\n",
    "\n",
    "dataset: join_language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import concurrent.futures as cf\n",
    "from time import perf_counter\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import ARRAY, String\n",
    "\n",
    "import pickle\n",
    "from keyword_extraction import DictLU_Extract_Exact\n",
    "\n",
    "#settings \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file for each language\n",
    "files_MeSH = glob('/home/ubuntu/ullrich/data/pickle/MeSH/*.p')\n",
    "files_agrovoc = glob('/home/ubuntu/ullrich/data/pickle/AGROVOC/*.p')\n",
    "\n",
    "def load_file(file_path):\n",
    "    [dicts_lower,dicts_upper] = pickle.load(open(file_path, \"rb\"))\n",
    "    DEE = DictLU_Extract_Exact(dicts_upper,dicts_lower)\n",
    "    return DEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(file_path, row, col_lang):\n",
    "    #load file for each language\n",
    "    for file in file_path:\n",
    "        parts = os.path.split(file)\n",
    "        parts = re.split(r'_|\\.', parts[1])\n",
    "        if parts[2] == 'en':\n",
    "            DEE_en = load_file(file)\n",
    "        elif parts[2] == 'de':\n",
    "            DEE_de = load_file(file)\n",
    "        elif parts[2] == 'fr':\n",
    "            DEE_fr = load_file(file)\n",
    "    #choose dict for the different languages\n",
    "    dicts = None\n",
    "    if col_lang == 'en':\n",
    "        dicts = DEE_en\n",
    "    elif col_lang == 'de':\n",
    "        dicts = DEE_de\n",
    "    elif col_lang == 'fr':\n",
    "        dicts = DEE_fr\n",
    "    #add terms and ID into list\n",
    "    if dicts is not None:\n",
    "        terms_id = []\n",
    "        terms = []\n",
    "        dicts.full(str(row))\n",
    "        res = dicts.result\n",
    "        for k, v in res.items():\n",
    "            terms_id.extend([str(k)] * v['count'])\n",
    "            terms.extend([str(v['term'])] * v['count'])\n",
    "        return terms_id, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_keyword_extraction(files, name):\n",
    "    chunksize = 10000\n",
    "    connect_string = 'postgresql+psycopg2://postgres:5050@localhost:5432/postgres'\n",
    "    sql_query = 'SELECT * FROM ke_stage.join_language'\n",
    "    \n",
    "    #create engine\n",
    "    engine = create_engine(connect_string)\n",
    "    connection = engine.connect().execution_options(stream_results=True, max_row_buffer=chunksize)\n",
    "    # create a process pool with 13 workers\n",
    "    executor = cf.ProcessPoolExecutor(max_workers=13)\n",
    "\n",
    "    start = perf_counter()\n",
    "    for chunk in pd.read_sql(sql_query, connection, chunksize=chunksize):\n",
    "        df_res = pd.DataFrame()\n",
    "        for i, row in chunk.iterrows():\n",
    "            #extract keywords for column title\n",
    "            future_title = executor.submit(get_keywords, files, row['title'], row['lang_title'])\n",
    "            result_title = future_title.result()\n",
    "            #extract keywords for column abstract\n",
    "            future_abs = executor.submit(get_keywords, files, row['abstract'], row['lang_abs'])\n",
    "            result_abs = future_abs.result()\n",
    "            if result_title or result_abs is not None:\n",
    "                if result_title is None:\n",
    "                    df_res = df_res._append({'dbrecordid': row['dbrecordid'], name +'_ID_title' : result_title , name + '_title': result_title, name + '_ID_abs' : result_abs[0] , name + '_abs': result_abs[1]}, ignore_index=True)\n",
    "                elif result_abs is None: \n",
    "                    df_res = df_res._append({'dbrecordid': row['dbrecordid'], name +'_ID_title' : result_title[0] , name + '_title': result_title[1], name + '_ID_abs' : result_abs , name + '_abs': result_abs}, ignore_index=True)    \n",
    "                else:\n",
    "                    df_res = df_res._append({'dbrecordid': row['dbrecordid'], name +'_ID_title' : result_title[0] , name + '_title': result_title[1] , name + '_ID_abs' : result_abs[0] , name + '_abs': result_abs[1]}, ignore_index=True)       \n",
    "        df_res.to_sql('corpus_keywords_' + name, engine, schema='ke_stage', chunksize=chunksize, if_exists='append', index=False, dtype={'dbrecordid': String(), name +'_ID_title': ARRAY(String()), name + '_title': ARRAY(String()), name + '_ID_abs': ARRAY(String()), name + '_abs': ARRAY(String())})\n",
    "        end = perf_counter()\n",
    "        elapsed_time = end - start\n",
    "        print('Edit ' + str(len(chunk)) + ' rows in ' + str(end) + ' s. Total: ' + str(elapsed_time) + ' s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_keyword_extraction(files_MeSH, 'MeSH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_keyword_extraction(files_agrovoc, 'AGROVOC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
