{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import os\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "import gensim as ge\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, nb_workers= 16, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define connection to db \n",
    "connect_string = 'postgresql+psycopg2://postgres:5050@localhost:5432/postgres'\n",
    "#define sql queries\n",
    "sql_query_agro = 'SELECT * FROM publ.corpus_keywords_agro'\n",
    "sql_query_mesh = 'SELECT * FROM publ.corpus_keywords_mesh'\n",
    "sql_query_class = 'SELECT * FROM ke_stage.corpus_small'\n",
    "#create engine\n",
    "engine = create_engine(connect_string)\n",
    "#read data as df\n",
    "df_agro = pd.read_sql(sql_query_agro, engine)\n",
    "df_mesh = pd.read_sql(sql_query_mesh, engine)\n",
    "df_class = pd.read_sql(sql_query_class, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the ids \n",
    "def join_id(df):\n",
    "    value = df['id1'].fillna(df['id2'])\n",
    "    df['id1'] = value\n",
    "    df = df.drop(['id2'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agro = join_id(df_agro)\n",
    "df_mesh = join_id(df_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both df (agrovoc and mesh)\n",
    "result = pd.merge(df_agro, df_mesh, on=['id1'], how='outer')\n",
    "#create list of all keywords for each document\n",
    "result['keywords'] = result.apply(lambda row: [val for val in row if isinstance(val, list)], axis=1)\n",
    "result.rename('id1':'dbrecordid')\n",
    "\n",
    "temp_list =  []\n",
    "for row in result['keywords']:\n",
    "    keywords_list = []\n",
    "    for l in row:\n",
    "        keywords_list.extend(l)\n",
    "    for x in range(len(keywords_list)):\n",
    "        keywords_list[x] = keywords_list[x].lower()\n",
    "    temp_list.append(keywords_list)\n",
    "    \n",
    "result['keywords_all'] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.merge(result, df_class, on=['dbrecordid'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test data\n",
    "df_train, df_test = train_test_split(result, test_size=0.25)\n",
    "\n",
    "#get list of keywords\n",
    "keywords_train = df_train['keywords_all'].tolist()\n",
    "keywords_test = df_test['keywords_all'].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = Pipeline([\n",
    "                ('vect', CountVectorizer(lowercase=False,stop_words=None,tokenizer=None)),\n",
    "                ('tfidf', TfidfTransformer(use_idf=True,norm=\"l2\")),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                        alpha=1e-3, random_state=42,\n",
    "                                        max_iter=5, tol=None))\n",
    "   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model.fit(keywords_train, classes['class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
