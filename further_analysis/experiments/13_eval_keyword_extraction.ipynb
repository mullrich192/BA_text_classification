{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import ARRAY, String\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download packages\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define connection to db \n",
    "connect_string = 'postgresql+psycopg2://postgres:5050@localhost:5432/postgres'\n",
    "#define sql queries\n",
    "query_corpus = 'SELECT dbrecordid, \"MeSH_title\", \"MeSH_abs\" FROM ke_stage.\"corpus_keywords_MeSH\"'\n",
    "query_golden = 'SELECT * FROM ke_stage.corpus_small_key_eval LIMIT 30000000'\n",
    "\n",
    "#create engine\n",
    "engine = create_engine(connect_string)\n",
    "#read data as df\n",
    "df_corpus = pd.read_sql(query_corpus, engine)\n",
    "df_golden = pd.read_sql(query_golden, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both dfs\n",
    "result = pd.merge(df_corpus, df_golden, on=['dbrecordid'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.to_csv('/home/ubuntu/ullrich/my_code/data/eval_keywords.csv', sep=',', encoding='utf-8')\n",
    "#result = pd.read_csv('/home/ubuntu/ullrich/my_code/data/eval_keywords.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result[:5000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the main topic, lower and lemmatize the words\n",
    "def clean_df(df):\n",
    "    res = [] \n",
    "    for row in df['mesh']:\n",
    "        temp = []\n",
    "        for item in row:\n",
    "            item = re.sub(r'\\/(.*)$','', item)\n",
    "            if ',' in item:\n",
    "                sublist = item.split(',')\n",
    "                sublist = [split_item.lower().strip() for split_item in sublist]\n",
    "                sublist2 =[]\n",
    "                for word in sublist:\n",
    "                    sublist2.append(lemmatizer.lemmatize(word))\n",
    "                temp.extend(sublist2)\n",
    "            else:\n",
    "                temp.append(lemmatizer.lemmatize(item.lower()))\n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nan-values with empty list\n",
    "def replace_nan(df, column):\n",
    "    df[column] = df[column].apply(lambda d: d if isinstance(d, list) else [])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['clean_mesh'] = clean_df(result)\n",
    "result = replace_nan(result,'clean_mesh')\n",
    "result = replace_nan(result,'MeSH_title')\n",
    "result = replace_nan(result,'MeSH_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbrecordid</th>\n",
       "      <th>MeSH_title</th>\n",
       "      <th>MeSH_abs</th>\n",
       "      <th>mesh</th>\n",
       "      <th>clean_mesh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M35920101</td>\n",
       "      <td>[risk reduction, australia, dementia, adults]</td>\n",
       "      <td>[primary care, government, research, education...</td>\n",
       "      <td>[Humans, Aged, Australia, Dementia/prevention ...</td>\n",
       "      <td>[human, aged, australia, dementia, risk reduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M35772114</td>\n",
       "      <td>[]</td>\n",
       "      <td>[health, health, will, environment, leadership...</td>\n",
       "      <td>[New Zealand, Delivery of Health Care, Humans,...</td>\n",
       "      <td>[new zealand, delivery of health care, human, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M34481326</td>\n",
       "      <td>[transient, brain, theta rhythms, architecture...</td>\n",
       "      <td>[brain, form]</td>\n",
       "      <td>[Oxytocin/administration &amp; dosage, Adult, Alph...</td>\n",
       "      <td>[oxytocin, adult, alpha rhythm, brain, brain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M35816696</td>\n",
       "      <td>[cyclization]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Cyclization, Esters, Peptides/chemistry]</td>\n",
       "      <td>[cyclization, ester, peptide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M32661566</td>\n",
       "      <td>[kinetics, river]</td>\n",
       "      <td>[river, phenotype, paper, nature, understandin...</td>\n",
       "      <td>[Ants/physiology, Animals, Adhesiveness, Adapt...</td>\n",
       "      <td>[ant, animal, adhesiveness, adaptation, physio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484351</th>\n",
       "      <td>SOMED546225</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cancer, cancer, cancer, cancer, mortality, mo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484352</th>\n",
       "      <td>AGRICOLAIND606461909</td>\n",
       "      <td>[cells, membranes, membranes, water]</td>\n",
       "      <td>[electrolysis, proton, membranes, membranes, m...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484353</th>\n",
       "      <td>M31483941</td>\n",
       "      <td>[human, light, light, skin, safety]</td>\n",
       "      <td>[goal, light, light, therapeutic, safety]</td>\n",
       "      <td>[Low-Level Light Therapy, Humans, Light, Skin/...</td>\n",
       "      <td>[low-level light therapy, human, light, skin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484354</th>\n",
       "      <td>AGRICOLAIND605914486</td>\n",
       "      <td>[microbial fuel cell]</td>\n",
       "      <td>[microalgae, membranes, membranes, microbial f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484355</th>\n",
       "      <td>M30100258</td>\n",
       "      <td>[stem cell, population]</td>\n",
       "      <td>[publications, statistics, stem cell niche, st...</td>\n",
       "      <td>[Radiation Tolerance, Animals, Colony-Forming ...</td>\n",
       "      <td>[radiation tolerance, animal, colony-forming u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484356 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dbrecordid  \\\n",
       "0                  M35920101   \n",
       "1                  M35772114   \n",
       "2                  M34481326   \n",
       "3                  M35816696   \n",
       "4                  M32661566   \n",
       "...                      ...   \n",
       "484351           SOMED546225   \n",
       "484352  AGRICOLAIND606461909   \n",
       "484353             M31483941   \n",
       "484354  AGRICOLAIND605914486   \n",
       "484355             M30100258   \n",
       "\n",
       "                                               MeSH_title  \\\n",
       "0           [risk reduction, australia, dementia, adults]   \n",
       "1                                                      []   \n",
       "2       [transient, brain, theta rhythms, architecture...   \n",
       "3                                           [cyclization]   \n",
       "4                                       [kinetics, river]   \n",
       "...                                                   ...   \n",
       "484351                                                 []   \n",
       "484352               [cells, membranes, membranes, water]   \n",
       "484353                [human, light, light, skin, safety]   \n",
       "484354                              [microbial fuel cell]   \n",
       "484355                            [stem cell, population]   \n",
       "\n",
       "                                                 MeSH_abs  \\\n",
       "0       [primary care, government, research, education...   \n",
       "1       [health, health, will, environment, leadership...   \n",
       "2                                           [brain, form]   \n",
       "3                                                      []   \n",
       "4       [river, phenotype, paper, nature, understandin...   \n",
       "...                                                   ...   \n",
       "484351  [cancer, cancer, cancer, cancer, mortality, mo...   \n",
       "484352  [electrolysis, proton, membranes, membranes, m...   \n",
       "484353          [goal, light, light, therapeutic, safety]   \n",
       "484354  [microalgae, membranes, membranes, microbial f...   \n",
       "484355  [publications, statistics, stem cell niche, st...   \n",
       "\n",
       "                                                     mesh  \\\n",
       "0       [Humans, Aged, Australia, Dementia/prevention ...   \n",
       "1       [New Zealand, Delivery of Health Care, Humans,...   \n",
       "2       [Oxytocin/administration & dosage, Adult, Alph...   \n",
       "3               [Cyclization, Esters, Peptides/chemistry]   \n",
       "4       [Ants/physiology, Animals, Adhesiveness, Adapt...   \n",
       "...                                                   ...   \n",
       "484351                                                 []   \n",
       "484352                                                 []   \n",
       "484353  [Low-Level Light Therapy, Humans, Light, Skin/...   \n",
       "484354                                                 []   \n",
       "484355  [Radiation Tolerance, Animals, Colony-Forming ...   \n",
       "\n",
       "                                               clean_mesh  \n",
       "0       [human, aged, australia, dementia, risk reduct...  \n",
       "1       [new zealand, delivery of health care, human, ...  \n",
       "2       [oxytocin, adult, alpha rhythm, brain, brain, ...  \n",
       "3                           [cyclization, ester, peptide]  \n",
       "4       [ant, animal, adhesiveness, adaptation, physio...  \n",
       "...                                                   ...  \n",
       "484351                                                 []  \n",
       "484352                                                 []  \n",
       "484353  [low-level light therapy, human, light, skin, ...  \n",
       "484354                                                 []  \n",
       "484355  [radiation tolerance, animal, colony-forming u...  \n",
       "\n",
       "[484356 rows x 5 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['clean_mesh'] = clean_df(test)\n",
    "test = replace_nan(test,'clean_mesh')\n",
    "test = replace_nan(test,'MeSH_title')\n",
    "test = replace_nan(test,'MeSH_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list with all keywords\n",
    "auto_keywords = list(result['MeSH_title'] + result['MeSH_abs'])\n",
    "true_keywords = result['clean_mesh'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(liste):\n",
    "    unique_lists = []\n",
    "    for sublist in liste:\n",
    "        unique_sublist = list(set(sublist))\n",
    "        unique_lists.append(unique_sublist)\n",
    "    return unique_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "auto_keywords = remove_duplicates(auto_keywords)\n",
    "true_keywords = remove_duplicates(true_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484356\n",
      "484356\n"
     ]
    }
   ],
   "source": [
    "print(len(auto_keywords))\n",
    "print(len(true_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radiation',\n",
       " 'atmosphere',\n",
       " 'algorithm',\n",
       " 'separation',\n",
       " 'methods',\n",
       " 'temperature',\n",
       " 'heat',\n",
       " 'chinese',\n",
       " 'dataset']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_keywords[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty the list, when parrallel list is empty\n",
    "def empty_lists(pred_l, true_l):\n",
    "    for i in range(len(pred_l)):\n",
    "        if not true_l[i]:  # check, if list is empty\n",
    "                pred_l[i] = []  \n",
    "    return pred_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_keywords = empty_lists(auto_keywords, true_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get same words from both lists (true positives)\n",
    "def get_intersection(extract_list, true_list):\n",
    "    res_liste =[]\n",
    "    for i in range(len(extract_list)):\n",
    "        res_liste.append(list(set(extract_list[i]).intersection(set(true_list[i]))))\n",
    "    return res_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_list_entities(liste):\n",
    "    count = 0\n",
    "    for each in liste:\n",
    "        count = count + len(each)\n",
    "    return count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tp = intersection beider listen\n",
    "- fp = kommt in auto_key aber nicht in intersection\n",
    "- tn = wörter in averbis aber nicht in intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22633776808531467\n"
     ]
    }
   ],
   "source": [
    "tp_count = count_list_entities(get_intersection(auto_keywords, true_keywords))\n",
    "total_averbis_count = count_list_entities(true_keywords)\n",
    "\n",
    "print(tp_count/total_averbis_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19553225776884528\n",
      "1604226.0\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5067\n"
     ]
    }
   ],
   "source": [
    "print(count_list_entitys(res_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28655\n"
     ]
    }
   ],
   "source": [
    "print(count_list_entitys(true_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = count_list_entities(true_keywords)\n",
    "fn2 = fn - tp_count\n",
    "#print(total_pred_count)\n",
    "#precision = tp_count / total_pred_count\n",
    "#recall = tp_count / tp_count + fn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in auto_keywords[:100]:\n",
    "    for y in true_keywords[:100]:      \n",
    "        matches = list(set(list1).intersection(list2))\n",
    "        #accuracy = match_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7, 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m matches \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(x)\u001b[39m.\u001b[39mintersection(y))\n\u001b[1;32m      4\u001b[0m \u001b[39m#matches = MultiLabelBinarizer().fit_transform(matches)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m pre \u001b[39m=\u001b[39m precision_score(y,x)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(pre)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1955\u001b[0m         y_true,\n\u001b[1;32m   1956\u001b[0m         y_pred,\n\u001b[1;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7, 24]"
     ]
    }
   ],
   "source": [
    "for x in auto_keywords[:100]:\n",
    "    for y in true_keywords[:100]:\n",
    "        matches = list(set(x).intersection(y))\n",
    "        #matches = MultiLabelBinarizer().fit_transform(matches)\n",
    "        pre = precision_score(y,x)\n",
    "        print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def pre_re(true_list, predicted_list):\n",
    "    # Berechnung der true positives (TP), false positives (FP) und false negatives (FN)\n",
    "    tp = len([1 for true, pred in zip(true_list, predicted_list) if pred in true])\n",
    "    fp = len([1 for pred in predicted_list if pred not in true_list])\n",
    "    fn = len([1 for true, pred in zip(true_list, predicted_list) if true not in pred])\n",
    "    \n",
    "    # Berechnung des Precision-Scores\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    # Berechnung des Recall-Scores\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    # Berechnung des F1-Scores\n",
    "    #f1 = 2 * (int(precision) * int(recall)) / (int(precision) + int(recall))\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.0\n",
      "recall 0.0\n"
     ]
    }
   ],
   "source": [
    "# Berechnung des F1-Scores\n",
    "precision, recall = pre_re(true_keywords, auto_keywords)\n",
    "\n",
    "#print(\"F1-Score:\", f1_score)\n",
    "print(\"precision:\", precision)\n",
    "print('recall', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "auto_keywords = mlb.fit([x for x in auto_keywords])\n",
    "true_keywords = mlb.fit([x for x in true_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(true_list, pred_list):\n",
    "    result = [] \n",
    "    tmp = {}\n",
    "    trues = [item in true_list for item in pred_list]\n",
    "    f1 = f1_score(trues, [True] * len(trues), average='weighted')\n",
    "    #result.append(tmp)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004433497536945813"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculation(true_keywords,auto_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(expected, predicted):\n",
    "    tp = 0  # True Positives\n",
    "    fp = 0  # False Positives\n",
    "    fn = 0  # False Negatives\n",
    "\n",
    "    for i in range(len(expected)):\n",
    "        for j in range(len(expected[i])):\n",
    "            if expected[i][j] in predicted[i]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "    for i in range(len(predicted)):\n",
    "        for j in range(len(predicted[i])):\n",
    "            if predicted[i][j] not in expected[i]:\n",
    "                fp += 1\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(expected, predicted):\n",
    "    expected = [x for x in expected]\n",
    "    predicted = [x for x in expected]  \n",
    "    tp = len(set(expected) & set(predicted))  # True Positives\n",
    "    fp = len(predicted) - tp  # False Positives\n",
    "    fn = len(expected) - tp  # False Negatives\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.07772199560715407\n",
      "Recall: 0.17746731148128247\n"
     ]
    }
   ],
   "source": [
    "precision, recall = calculate_precision_recall(true_keywords, auto_keywords)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nur Englische Terme wurden annotiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc_score(combinations, pred_class):\n",
    "    result = [] \n",
    "    total_count = len(pred_class)\n",
    "    match_count = 0\n",
    "    for item in pred_class:\n",
    "        if item in combinations:\n",
    "            match_count = match_count + 1\n",
    "            print(item)\n",
    "    #print(match_count)        \n",
    "    accuracy = match_count / total_count\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
