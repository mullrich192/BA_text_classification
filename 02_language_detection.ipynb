{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection\n",
    "\n",
    "### identify language for title and abstract\n",
    "\n",
    "dataset: corpus_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import concurrent.futures as cf\n",
    "from time import perf_counter\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect language for column title and abstract\n",
    "def detect_language(row):\n",
    "    try:\n",
    "        \n",
    "        if not isinstance(row, str):\n",
    "            if len(row) != 0:          \n",
    "                row = row[0]\n",
    "            else:\n",
    "                row= \"_\"                    \n",
    "        return detect(row)\n",
    "    \n",
    "    except LangDetectException:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lang_detection():\n",
    "    chunksize = 10000\n",
    "    connect_string = 'postgresql+psycopg2://postgres:5050@localhost:5432/postgres'\n",
    "    sql_query = 'SELECT dbrecordid, title, abstract FROM ke_stage.corpus_small'\n",
    "\n",
    "    #create enginge\n",
    "    engine = create_engine(connect_string)\n",
    "    connection = engine.connect().execution_options(stream_results=True, max_row_buffer=chunksize)\n",
    "    # create a process pool with 13 workers\n",
    "    executor = cf.ProcessPoolExecutor(max_workers=13)\n",
    "    start = perf_counter()\n",
    "    for chunk in pd.read_sql(sql_query, connection, chunksize=chunksize):\n",
    "        df_res = pd.DataFrame()\n",
    "        for i, row in chunk.iterrows():\n",
    "            #execute function for column title\n",
    "            future_title = executor.submit(detect_language, row['title'])\n",
    "            detected_lang_title = future_title.result()\n",
    "            #execute function for column abstract\n",
    "            future_abs = executor.submit(detect_language, row['abstract'])\n",
    "            detected_lang_abs = future_abs.result()\n",
    "            #append to new dataframe\n",
    "            df_res = df_res.append({'dbrecordid': row['dbrecordid'], 'lang_title': detected_lang_title, 'lang_abs': detected_lang_abs}, ignore_index=True)\n",
    "        df_res.to_sql('corpus_language', engine, schema='ke_stage', chunksize=chunksize, if_exists='append', index=False)\n",
    "        end = perf_counter()\n",
    "        elapsed_time = end - start\n",
    "        print('Edited next ' + str(len(chunk)) + ' rows ( run count: '+ str(i) +') in total ' + str(elapsed_time) + ' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edited next 10000 rows ( run count: 9999) in total 161.7435262040235 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 318.4016227830434 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 472.59154005604796 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 628.1455237549962 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 780.8002946439665 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 933.1420923559926 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 1085.5628438510466 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 1236.8583683560137 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 1389.9135940540582 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 1544.3650100049563 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 1697.541013419046 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 1853.3432220870163 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 2007.140580923995 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 2157.8810990180355 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 2305.4547302130377 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 2454.0263188920217 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 2602.7929225959815 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 2752.589004712063 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 2903.967678394052 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 3054.7472758230288 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 3205.571302901022 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 3352.9786984630628 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 3501.314041848993 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 3648.821092720027 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 3799.50001647498 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 3953.109334631008 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 4108.978093779995 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 4265.693468902959 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 4420.6520212610485 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 4575.471201287 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 4729.16225390404 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 4884.709972372977 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 5039.908937699045 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 5193.566062633996 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 5348.170178479981 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 5503.719868551008 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 5660.59928566101 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 5816.514982808032 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 5972.813201571 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 6129.030392225017 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 6284.488297943026 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 6440.83288457396 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 6596.560717641027 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 6751.637785237981 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 6906.446352679981 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 7061.817881469033 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 7217.91027399397 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 7369.815380641958 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 7521.492434786051 s\n",
      "Edited next 10000 rows ( run count: 9999) in total 7675.911198302056 s\n"
     ]
    }
   ],
   "source": [
    "process_lang_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
